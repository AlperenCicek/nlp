{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'orjinal yanlış iddia itibarıyla küsür şoför iddaa itibarıyla yanlış küsur iddia ajitasyon küsur yanlış itibarıyla acıtasyon küsur itibarıyla iddia orijinal şoför küsur yanlış iddaa küsur orjinal  şöför orijinal iddaa orijinal iddia ajitasyon orijinal itibarıyla şoför iddia ajitasyon itibariyle yanlış orijinal şöför yalnış itibarıyla acıtasyon iddia itibariyle şöför yanlış ajitasyon  şöför küsür itibariyle şoför acıtasyon itibarıyla şoför iddia acıtasyon küsur iddia şoför ajitasyon yalnış orijinal iddia ajitasyon şoför küsür'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"orjinal yanlış iddia itibarıyla küsür şoför iddaa itibarıyla yanlış küsur iddia ajitasyon küsur yanlış itibarıyla acıtasyon küsur itibarıyla iddia orijinal şoför küsur yanlış iddaa küsur orjinal  şöför orijinal iddaa orijinal iddia ajitasyon orijinal itibarıyla şoför iddia ajitasyon itibariyle yanlış orijinal şöför yalnış itibarıyla acıtasyon iddia itibariyle şöför yanlış ajitasyon  şöför küsür itibariyle şoför acıtasyon itibarıyla şoför iddia acıtasyon küsur iddia şoför ajitasyon yalnış orijinal iddia ajitasyon şoför küsür\"\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['orjinal',\n",
       " 'yanlış',\n",
       " 'iddia',\n",
       " 'itibarıyla',\n",
       " 'küsür',\n",
       " 'şoför',\n",
       " 'iddaa',\n",
       " 'itibarıyla',\n",
       " 'yanlış',\n",
       " 'küsur',\n",
       " 'iddia',\n",
       " 'ajitasyon',\n",
       " 'küsur',\n",
       " 'yanlış',\n",
       " 'itibarıyla',\n",
       " 'acıtasyon',\n",
       " 'küsur',\n",
       " 'itibarıyla',\n",
       " 'iddia',\n",
       " 'orijinal',\n",
       " 'şoför',\n",
       " 'küsur',\n",
       " 'yanlış',\n",
       " 'iddaa',\n",
       " 'küsur',\n",
       " 'orjinal',\n",
       " 'şöför',\n",
       " 'orijinal',\n",
       " 'iddaa',\n",
       " 'orijinal',\n",
       " 'iddia',\n",
       " 'ajitasyon',\n",
       " 'orijinal',\n",
       " 'itibarıyla',\n",
       " 'şoför',\n",
       " 'iddia',\n",
       " 'ajitasyon',\n",
       " 'itibariyle',\n",
       " 'yanlış',\n",
       " 'orijinal',\n",
       " 'şöför',\n",
       " 'yalnış',\n",
       " 'itibarıyla',\n",
       " 'acıtasyon',\n",
       " 'iddia',\n",
       " 'itibariyle',\n",
       " 'şöför',\n",
       " 'yanlış',\n",
       " 'ajitasyon',\n",
       " 'şöför',\n",
       " 'küsür',\n",
       " 'itibariyle',\n",
       " 'şoför',\n",
       " 'acıtasyon',\n",
       " 'itibarıyla',\n",
       " 'şoför',\n",
       " 'iddia',\n",
       " 'acıtasyon',\n",
       " 'küsur',\n",
       " 'iddia',\n",
       " 'şoför',\n",
       " 'ajitasyon',\n",
       " 'yalnış',\n",
       " 'orijinal',\n",
       " 'iddia',\n",
       " 'ajitasyon',\n",
       " 'şoför',\n",
       " 'küsür']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "each_word = RegexpTokenizer(r'\\w+').tokenize(data)\n",
    "tokens = []\n",
    "for element in each_word:\n",
    "    tokens.append(element.lower())\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatingUniqueWordList(data):\n",
    "    word_list = []\n",
    "    for i in range(len(data)):\n",
    "        count = 0\n",
    "        isItThereOnList = False\n",
    "        for j in range(len(data)):\n",
    "            if data[i] == data[j]:\n",
    "                count = count + 1\n",
    "        for k in range(len(word_list)):\n",
    "            if word_list[k][0] == data[i]:\n",
    "                isItThereOnList = True\n",
    "        if isItThereOnList != True:\n",
    "            word_list.append([data[i], count])\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['orjinal', 2],\n",
       " ['yanlış', 6],\n",
       " ['iddia', 9],\n",
       " ['itibarıyla', 7],\n",
       " ['küsür', 3],\n",
       " ['şoför', 7],\n",
       " ['iddaa', 3],\n",
       " ['küsur', 6],\n",
       " ['ajitasyon', 6],\n",
       " ['acıtasyon', 4],\n",
       " ['orijinal', 6],\n",
       " ['şöför', 4],\n",
       " ['itibariyle', 3],\n",
       " ['yalnış', 2]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_freq = creatingUniqueWordList(tokens)\n",
    "tokens_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordsLessThan(num, data):\n",
    "    words_more_than = []\n",
    "    for i in range(len(data)):\n",
    "        if data[i][1] < num:\n",
    "            words_more_than.append(data[i])\n",
    "    return words_more_than"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['orjinal', 2],\n",
       " ['küsür', 3],\n",
       " ['iddaa', 3],\n",
       " ['acıtasyon', 4],\n",
       " ['şöför', 4],\n",
       " ['itibariyle', 3],\n",
       " ['yalnış', 2]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = wordsLessThan(5, tokens_freq)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshteinDistanceDP(token1, token2, printFunc = False):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "    if printFunc:\n",
    "        for t1 in range(len(token1) + 1):\n",
    "            for t2 in range(len(token2) + 1):\n",
    "                print(int(distances[t1][t2]), end=\" \")\n",
    "            print()\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 \n",
      "1 0 1 2 3 4 5 6 7 \n",
      "2 1 1 2 3 3 4 5 6 \n",
      "3 2 2 2 3 4 3 4 5 \n",
      "4 3 2 3 3 4 4 3 4 \n",
      "5 4 3 3 4 4 5 4 3 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshteinDistanceDP(\"naber\", \"ne haber\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 \n",
      "1 1 2 3 4 5 6 \n",
      "2 1 2 3 4 5 6 \n",
      "3 2 1 2 3 4 5 \n",
      "4 3 2 1 2 3 4 \n",
      "5 4 3 2 1 2 3 \n",
      "6 5 4 3 2 1 2 \n",
      "7 6 5 4 3 2 1 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshteinDistanceDP(\"abcçdef\", \"bcçdef\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSimilar(dataSet, word):\n",
    "    minSimilarityWieight = 10\n",
    "    similarWord = \"\"\n",
    "    for element in dataSet:\n",
    "        weight = levenshteinDistanceDP(element, word)\n",
    "        if  weight < minSimilarityWieight and element != word:\n",
    "            minSimilarityWieight= weight\n",
    "            similarWord = element\n",
    "    return similarWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG  ->  TRUE\n",
      "orjinal -> orijinal\n",
      "küsür -> küsur\n",
      "iddaa -> iddia\n",
      "acıtasyon -> ajitasyon\n",
      "şöför -> şoför\n",
      "itibariyle -> itibarıyla\n",
      "yalnış -> yanlış\n"
     ]
    }
   ],
   "source": [
    "print(\"WRONG  ->  TRUE\")\n",
    "for element in words:\n",
    "    if findSimilar(tokens, element[0]) != None:\n",
    "        print(element[0], \"->\", findSimilar(tokens, element[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
